{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109424ce-53e7-4268-8fbd-b59ea89355f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd210b-4188-40cd-8944-5307694480f6",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this homework, we will use the California Housing Prices from [Kaggle](https://www.kaggle.com/datasets/camnugent/california-housing-prices).\n",
    "\n",
    "Here's a wget-able [link](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv):\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\n",
    "```\n",
    "\n",
    "The goal of this homework is to create a regression model for predicting housing prices (column `'median_house_value'`).\n",
    "\n",
    "\n",
    "### Preparing the dataset \n",
    "\n",
    "For this homework, we only want to use a subset of data. This is the same subset we used in homework #2.\n",
    "\n",
    "First, keep only the records where `ocean_proximity` is either `'<1H OCEAN'` or `'INLAND'`\n",
    "\n",
    "Preparation:\n",
    "\n",
    "* Fill missing values with zeros.\n",
    "* Apply the log tranform to `median_house_value`.\n",
    "* Do train/validation/test split with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1.\n",
    "* Use `DictVectorizer(sparse=True)` to turn the dataframe into matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "667ef687-07b6-4184-907c-8aed6e3a1227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/housing.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c546c7e9-0c1c-4ae9-a61c-68b16c099ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocean_proximity\n",
       "<1H OCEAN     9136\n",
       "INLAND        6551\n",
       "NEAR OCEAN    2658\n",
       "NEAR BAY      2290\n",
       "ISLAND           5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ocean_proximity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a4f0675-2909-4f85-8272-a4bd1acaa463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, keep only the records where ocean_proximity is either '<1H OCEAN' or 'INLAND'\n",
    "df = data.loc[(data.ocean_proximity == '<1H OCEAN') | (data.ocean_proximity == 'INLAND')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "460b9b51-a799-4ec7-a3b8-325beedd37e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocean_proximity\n",
       "<1H OCEAN    9136\n",
       "INLAND       6551\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ocean_proximity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "749eff16-b7b6-4878-974e-55295871e73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        157\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a3adef0-48ca-4417-aeb4-09a01ca55661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with zeros.\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "304f90fc-4e5c-4133-a8b6-e0ec0cee9655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             0\n",
       "latitude              0\n",
       "housing_median_age    0\n",
       "total_rooms           0\n",
       "total_bedrooms        0\n",
       "population            0\n",
       "households            0\n",
       "median_income         0\n",
       "median_house_value    0\n",
       "ocean_proximity       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b8970c1-4b6c-46ee-903a-bfd304f40741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701    431000.0\n",
       "830    217000.0\n",
       "859    247600.0\n",
       "860    283500.0\n",
       "861    216900.0\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before\n",
    "df.median_house_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43ef6a35-6dcc-4194-b2cd-f5fd1e683785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the log tranform to median_house_value\n",
    "df['median_house_value'] = np.log1p(df['median_house_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38fa5b0d-d88c-4226-abea-64ac5df6d718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701    12.973866\n",
       "830    12.287657\n",
       "859    12.419574\n",
       "860    12.554971\n",
       "861    12.287196\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.median_house_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7484de7-68df-4304-b311-aa0cb2e853f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do train/validation/test split with 60%/20%/20% distribution.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5eb80a9-6600-4f9b-91b9-4859dc33cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_train_full, test_size=0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00b3980d-7d0c-4e6c-be28-b40eef6f0d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12549, 9411, 3138, 3138)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_full), len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f862ae48-9805-4ca3-8435-01ec58876974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DictVectorizer(sparse=True) to turn the dataframe into matrices.\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30437590-1c17-4fc3-aa59-aa51d8882191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dfs(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "    df_train, df_val = train_test_split(df_train_full, test_size=0.25, random_state=1)\n",
    "\n",
    "    y_train_full = df_train_full['median_house_value'].values\n",
    "    y_train = df_train['median_house_value'].values\n",
    "    y_val = df_val['median_house_value'].values\n",
    "    y_test = df_test['median_house_value'].values\n",
    "\n",
    "    del df_train_full['median_house_value']\n",
    "    del df_train['median_house_value']\n",
    "    del df_val['median_house_value']\n",
    "    del df_test['median_house_value']\n",
    "\n",
    "    return df_train_full, df_train, df_val, df_test, y_train_full, y_train, y_val, y_test\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a239553-f6c0-4b71-9963-2ebb747d5a2d",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the `median_house_value` variable. \n",
    "\n",
    "* Train a model with `max_depth=1`.\n",
    "\n",
    "\n",
    "Which feature is used for splitting the data?\n",
    "\n",
    "* `ocean_proximity`\n",
    "* `total_rooms`\n",
    "* `latitude`\n",
    "* `population`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "009b0b10-feda-4c25-9302-2c9d0b7e7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full, df_train, df_val, df_test, y_train_full, y_train, y_val, y_test = prepare_dfs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc4487c0-2bda-4f6d-a641-33246ebc00a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, export_text\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import export_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ec507f6-1046-49ea-b767-19081b5cc977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45168599736547216"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "dicts_train = df_train.to_dict(orient='records')\n",
    "dicts_val = df_val.to_dict(orient='records')\n",
    "\n",
    "X_train = dv.fit_transform(dicts_train)\n",
    "X_val = dv.transform(dicts_val)\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=1) \n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11e27f97-db1e-43b7-956a-8a25b3fd2bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- ocean_proximity=<1H OCEAN <= 0.50\n",
      "|   |--- value: [11.61]\n",
      "|--- ocean_proximity=<1H OCEAN >  0.50\n",
      "|   |--- value: [12.30]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(export_text(dt, feature_names=dv.feature_names_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb22f8f-760f-4eac-9fc8-12a06fc9995b",
   "metadata": {},
   "source": [
    "answer: ocean_proximity=<1H OCEAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd98d3-7072-4cf1-bf96-d2b5441a935b",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1` (optional - to make training faster)\n",
    "\n",
    "\n",
    "What's the RMSE of this model on validation?\n",
    "\n",
    "* 0.045\n",
    "* 0.245\n",
    "* 0.545\n",
    "* 0.845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28098f83-ec14-4876-8bf1-e0ec3ca5613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9cdc7fef-1e6f-4dec-b80c-e24f2ecdcb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24472888684076877"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# dicts_train = df_train.to_dict(orient='records')\n",
    "# dicts_val = df_val.to_dict(orient='records')\n",
    "\n",
    "# X_train = dv.fit_transform(dicts_train)\n",
    "# X_val = dv.transform(dicts_val)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1) \n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293af12-643f-42d1-9e93-fa6071b34080",
   "metadata": {},
   "source": [
    "answer: 0.245"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae468037-e4cc-4ffe-8440-5f6038791132",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10.\n",
    "* Set `random_state` to `1`.\n",
    "* Evaluate the model on the validation dataset.\n",
    "\n",
    "\n",
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "\n",
    "- 10\n",
    "- 25\n",
    "- 50\n",
    "- 160\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfd55bdd-2826-49b8-9ad6-2801fb5b5d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 10 ---->  0.24473\n",
      "\n",
      "n_estimators: 20 ---->  0.23825\n",
      "\n",
      "n_estimators: 30 ---->  0.23623\n",
      "\n",
      "n_estimators: 40 ---->  0.23458\n",
      "\n",
      "n_estimators: 50 ---->  0.23449\n",
      "\n",
      "n_estimators: 60 ---->  0.23415\n",
      "\n",
      "n_estimators: 70 ---->  0.23415\n",
      "\n",
      "n_estimators: 80 ---->  0.23431\n",
      "\n",
      "n_estimators: 90 ---->  0.2343\n",
      "\n",
      "n_estimators: 100 ---->  0.23416\n",
      "\n",
      "n_estimators: 110 ---->  0.23413\n",
      "\n",
      "n_estimators: 120 ---->  0.23386\n",
      "\n",
      "n_estimators: 130 ---->  0.23377\n",
      "\n",
      "n_estimators: 140 ---->  0.23362\n",
      "\n",
      "n_estimators: 150 ---->  0.23351\n",
      "\n",
      "n_estimators: 160 ---->  0.23332\n",
      "\n",
      "n_estimators: 170 ---->  0.23332\n",
      "\n",
      "n_estimators: 180 ---->  0.23352\n",
      "\n",
      "n_estimators: 190 ---->  0.2338\n",
      "\n",
      "n_estimators: 200 ---->  0.23374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(10, 201, 10):\n",
    "    # dv = DictVectorizer(sparse=False)\n",
    "\n",
    "    # dicts_train = df_train.to_dict(orient='records')\n",
    "    # dicts_val = df_val.to_dict(orient='records')\n",
    "    \n",
    "    # X_train = dv.fit_transform(dicts_train)\n",
    "    # X_val = dv.transform(dicts_val)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1) \n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "    rmse = round(mean_squared_error(y_val, y_pred, squared=False), 5)\n",
    "    \n",
    "    print(f\"n_estimators: {n} ---->  {rmse}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fd88b7-7793-48a1-b7de-f15224c0972d",
   "metadata": {},
   "source": [
    "answer: I am going to say 160 because the question didnt say anything about rounding the rmse to 3 points, otherwise I would say 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e724a75-b26e-4472-8367-f5a5c414a0de",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values, try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "* Fix the random seed: `random_state=1`\n",
    "\n",
    "\n",
    "What's the best `max_depth`:\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02a50981-d9b0-4739-b064-964e233091ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 10\n",
      "\n",
      "    n_estimators: 10         ---->  0.25051\n",
      "    n_estimators: 20         ---->  0.24726\n",
      "    n_estimators: 30         ---->  0.24626\n",
      "    n_estimators: 40         ---->  0.24509\n",
      "    n_estimators: 50         ---->  0.24562\n",
      "    n_estimators: 60         ---->  0.24547\n",
      "    n_estimators: 70         ---->  0.24544\n",
      "    n_estimators: 80         ---->  0.24561\n",
      "    n_estimators: 90         ---->  0.24550\n",
      "    n_estimators: 100        ---->  0.24538\n",
      "    n_estimators: 110        ---->  0.24527\n",
      "    n_estimators: 120        ---->  0.24500\n",
      "    n_estimators: 130        ---->  0.24476\n",
      "    n_estimators: 140        ---->  0.24459\n",
      "    n_estimators: 150        ---->  0.24455\n",
      "    n_estimators: 160        ---->  0.24445\n",
      "    n_estimators: 170        ---->  0.24439\n",
      "    n_estimators: 180        ---->  0.24449\n",
      "    n_estimators: 190        ---->  0.24469\n",
      "    n_estimators: 200        ---->  0.24473\n",
      "avg rmse 0.245453\n",
      "max_depth: 15\n",
      "\n",
      "    n_estimators: 10         ---->  0.24553\n",
      "    n_estimators: 20         ---->  0.23892\n",
      "    n_estimators: 30         ---->  0.23694\n",
      "    n_estimators: 40         ---->  0.23570\n",
      "    n_estimators: 50         ---->  0.23592\n",
      "    n_estimators: 60         ---->  0.23551\n",
      "    n_estimators: 70         ---->  0.23541\n",
      "    n_estimators: 80         ---->  0.23566\n",
      "    n_estimators: 90         ---->  0.23542\n",
      "    n_estimators: 100        ---->  0.23522\n",
      "    n_estimators: 110        ---->  0.23511\n",
      "    n_estimators: 120        ---->  0.23474\n",
      "    n_estimators: 130        ---->  0.23466\n",
      "    n_estimators: 140        ---->  0.23454\n",
      "    n_estimators: 150        ---->  0.23445\n",
      "    n_estimators: 160        ---->  0.23424\n",
      "    n_estimators: 170        ---->  0.23418\n",
      "    n_estimators: 180        ---->  0.23445\n",
      "    n_estimators: 190        ---->  0.23465\n",
      "    n_estimators: 200        ---->  0.23453\n",
      "avg rmse 0.23578900000000003\n",
      "max_depth: 20\n",
      "\n",
      "    n_estimators: 10         ---->  0.24456\n",
      "    n_estimators: 20         ---->  0.23821\n",
      "    n_estimators: 30         ---->  0.23616\n",
      "    n_estimators: 40         ---->  0.23457\n",
      "    n_estimators: 50         ---->  0.23435\n",
      "    n_estimators: 60         ---->  0.23429\n",
      "    n_estimators: 70         ---->  0.23424\n",
      "    n_estimators: 80         ---->  0.23454\n",
      "    n_estimators: 90         ---->  0.23426\n",
      "    n_estimators: 100        ---->  0.23423\n",
      "    n_estimators: 110        ---->  0.23421\n",
      "    n_estimators: 120        ---->  0.23412\n",
      "    n_estimators: 130        ---->  0.23388\n",
      "    n_estimators: 140        ---->  0.23364\n",
      "    n_estimators: 150        ---->  0.23350\n",
      "    n_estimators: 160        ---->  0.23340\n",
      "    n_estimators: 170        ---->  0.23341\n",
      "    n_estimators: 180        ---->  0.23358\n",
      "    n_estimators: 190        ---->  0.23382\n",
      "    n_estimators: 200        ---->  0.23372\n",
      "avg rmse 0.2348345\n",
      "max_depth: 25\n",
      "\n",
      "    n_estimators: 10         ---->  0.24378\n",
      "    n_estimators: 20         ---->  0.23809\n",
      "    n_estimators: 30         ---->  0.23637\n",
      "    n_estimators: 40         ---->  0.23448\n",
      "    n_estimators: 50         ---->  0.23455\n",
      "    n_estimators: 60         ---->  0.23418\n",
      "    n_estimators: 70         ---->  0.23404\n",
      "    n_estimators: 80         ---->  0.23434\n",
      "    n_estimators: 90         ---->  0.23424\n",
      "    n_estimators: 100        ---->  0.23407\n",
      "    n_estimators: 110        ---->  0.23404\n",
      "    n_estimators: 120        ---->  0.23381\n",
      "    n_estimators: 130        ---->  0.23376\n",
      "    n_estimators: 140        ---->  0.23354\n",
      "    n_estimators: 150        ---->  0.23347\n",
      "    n_estimators: 160        ---->  0.23340\n",
      "    n_estimators: 170        ---->  0.23340\n",
      "    n_estimators: 180        ---->  0.23363\n",
      "    n_estimators: 190        ---->  0.23389\n",
      "    n_estimators: 200        ---->  0.23374\n",
      "avg rmse 0.234741\n",
      "\n",
      "The lowest rmse was 0.2334 at a max_depth of 20, and n_esitmators of 160\n"
     ]
    }
   ],
   "source": [
    "min_rmse = float('inf')\n",
    "\n",
    "for d in [10, 15, 20, 25]:\n",
    "    print(f\"max_depth: {d}\")\n",
    "    print()\n",
    "    rmses = []\n",
    "    \n",
    "    for n in range(10, 201, 10):\n",
    "    \n",
    "    \n",
    "        rf = RandomForestRegressor(n_estimators=n, max_depth=d, random_state=1, n_jobs=-1) \n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_val)\n",
    "        rmse = round(mean_squared_error(y_val, y_pred, squared=False), 5)\n",
    "        if rmse < min_rmse:\n",
    "            min_rmse = rmse\n",
    "            res = (d, n, rmse)\n",
    "        rmses.append(rmse)\n",
    "        \n",
    "        print(f\"    n_estimators: {n:<10} ---->  {rmse:.5f}\")\n",
    "        # print()\n",
    "    avg_rmse = np.mean(rmses)\n",
    "    print(f\"avg rmse {avg_rmse}\")\n",
    "\n",
    "best_md, best_n_esitmators, best_rmse = res\n",
    "print()\n",
    "print(f\"The lowest rmse was {best_rmse} at a max_depth of {best_md}, and n_esitmators of {best_n_esitmators}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbef7b8-8ca6-47b1-bb5d-d0be3961abea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
