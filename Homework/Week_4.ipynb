{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4 Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import auc, roc_auc_score, precision_recall_curve, precision_score, recall_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import and prep\n",
    "df = pd.read_csv('AER_credit_card_data.csv')\n",
    "df['target'] = np.where(df['card']=='yes', 1,0)\n",
    "\n",
    "X = df.drop(columns=['target','card'])\n",
    "y = df['target']\n",
    "# Split into test and train at 60/40\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=1)\n",
    "\n",
    "# now split into train and validation to give 60/20/20 split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for reports column: 0.660960591133005\n",
      "AUC for dependents column: 0.542816091954023\n",
      "AUC for active column: 0.6282019704433498\n",
      "AUC for share column: 0.9814039408866996\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "numeric = ['reports', 'dependents', 'active','share'] \n",
    "\n",
    "for variable in numeric:\n",
    "    model = LogisticRegression(solver=\"liblinear\", random_state=1)\n",
    "    train = X_train[variable].to_numpy().reshape(-1,1)\n",
    "    model.fit(train, y_train)\n",
    "    score = roc_auc_score(y_train, model.predict_proba(train)[:, 1])\n",
    "    print(f\"AUC for {variable} column: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "\n",
    "def df_prep_and_split(df):\n",
    "    df = df[[\"target\",\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"]]\n",
    "\n",
    "    X = df.drop(columns=['target'])\n",
    "    y = df['target']\n",
    "    # Split into test and train at 60/40\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=1)\n",
    "\n",
    "    # now split into train and validation to give 60/20/20 split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=1)\n",
    "\n",
    "    categoric = ['owner','selfemp']\n",
    "    numeric = ['reports',\t'age',\t'income',\t'share',\t'expenditure',\t'dependents',\t'months',\t'majorcards',\t'active']\n",
    "    # One hot encode categoricals using a dict vectorizer\n",
    "    train_dict = X_train[categoric + numeric].to_dict(orient='records')\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    dv.fit(train_dict)\n",
    "    X_train = dv.transform(train_dict)\n",
    "\n",
    "    # One hot encode validation data for model metrics\n",
    "    val_dict = X_val[categoric + numeric].to_dict(orient='records')\n",
    "    X_val = dv.transform(val_dict)\n",
    "\n",
    "    return X_train, X_test, y_train, X_val, y_test, y_val\n",
    "\n",
    "X_train, X_test, y_train, X_val, y_test, y_val = df_prep_and_split(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC is: 0.99984\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "score = roc_auc_score(y_val, model.predict_proba(X_val)[:, 1])\n",
    "print(f\"AUC is: {round(score,5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Threshold', ylabel='Recall'>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 3\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    recall = recall_score(y_val, y_pred >= threshold)\n",
    "    precision_scores.append(recall)\n",
    "    precision = precision_score(y_val, y_pred >= threshold)\n",
    "    recall_scores.append(precision)\n",
    "\n",
    "plt_df = pd.DataFrame(list(zip(thresholds, recall_scores, precision_scores)),\n",
    "               columns =['Threshold', 'Recall', 'Precision'])\n",
    "sns.lineplot(x='Threshold', y='Recall', data=plt_df)\n",
    "sns.lineplot(x='Threshold', y='Precision', data=plt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curves intersect at 0.3 Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 4 \n",
    "# Use the dataframe created to make above plot to create new column for F1 scores\n",
    "plt_df['F1_score'] = 2 * plt_df['Precision'] * plt_df['Recall'] / (plt_df['Precision'] + plt_df['Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>0.997519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold  Recall  Precision  F1_score\n",
       "45       0.45     1.0    0.99505  0.997519\n",
       "46       0.46     1.0    0.99505  0.997519\n",
       "47       0.47     1.0    0.99505  0.997519\n",
       "48       0.48     1.0    0.99505  0.997519\n",
       "49       0.49     1.0    0.99505  0.997519\n",
       "50       0.50     1.0    0.99505  0.997519\n",
       "51       0.51     1.0    0.99505  0.997519\n",
       "52       0.52     1.0    0.99505  0.997519\n",
       "53       0.53     1.0    0.99505  0.997519\n",
       "54       0.54     1.0    0.99505  0.997519\n",
       "55       0.55     1.0    0.99505  0.997519\n",
       "56       0.56     1.0    0.99505  0.997519\n",
       "57       0.57     1.0    0.99505  0.997519\n",
       "58       0.58     1.0    0.99505  0.997519\n",
       "59       0.59     1.0    0.99505  0.997519\n",
       "60       0.60     1.0    0.99505  0.997519\n",
       "61       0.61     1.0    0.99505  0.997519\n",
       "62       0.62     1.0    0.99505  0.997519\n",
       "63       0.63     1.0    0.99505  0.997519\n",
       "64       0.64     1.0    0.99505  0.997519\n",
       "65       0.65     1.0    0.99505  0.997519\n",
       "66       0.66     1.0    0.99505  0.997519\n",
       "67       0.67     1.0    0.99505  0.997519"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_F1 = plt_df['F1_score'].max()\n",
    "plt_df[plt_df['F1_score']==max_F1]\n",
    "# based on below output the max F1 score appears arouund 0.4 Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Question 5\n",
    "\n",
    "# # Create function to run k fold validation\n",
    "# # Create df_train_full\n",
    "# def k_folds_validation(df, kfoldsplit):\n",
    "\n",
    "#     kfold = KFold(n_splits=kfoldsplit, shuffle=True, random_state=1)\n",
    "\n",
    "\n",
    "#     # Use functions from Learning material\n",
    "#     def train(df, y):\n",
    "#         cat = df[categoric + numeric].to_dict(orient='records')\n",
    "        \n",
    "#         dv = DictVectorizer(sparse=False)\n",
    "#         dv.fit(cat)\n",
    "\n",
    "#         X = dv.transform(cat)\n",
    "\n",
    "#         model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "#         model.fit(X, y)\n",
    "\n",
    "#         return dv, model\n",
    "\n",
    "\n",
    "#     def predict(df, dv, model):\n",
    "#         cat = df[categoric + numeric].to_dict(orient='records')\n",
    "        \n",
    "#         X = dv.transform(cat)\n",
    "\n",
    "#         y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "#         return y_pred\n",
    "\n",
    "\n",
    "\n",
    "#     df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "#     df_train, df_val = train_test_split(df_train_full, test_size=0.33, random_state=11)\n",
    "\n",
    "#     y_train = df_train['target'].values\n",
    "#     y_val = df_val['target'].values\n",
    "\n",
    "#     del df_train['target']\n",
    "#     del df_val['target']\n",
    "\n",
    "\n",
    "#     # get Kfolds AUCs - using code from the learning material\n",
    "#     aucs = []\n",
    "\n",
    "#     for train_idx, val_idx in kfold.split(df_train_full):\n",
    "#         df_train = df_train_full.iloc[train_idx]\n",
    "#         y_train = df_train['target'].values\n",
    "\n",
    "#         df_val = df_train_full.iloc[val_idx]\n",
    "#         y_val = df_val['target'].values\n",
    "\n",
    "#         dv, model = train(df_train, y_train)\n",
    "#         y_pred = predict(df_val, dv, model)\n",
    "\n",
    "#         rocauc = roc_auc_score(y_val, y_pred)\n",
    "#         aucs.append(rocauc)\n",
    "    \n",
    "#     return aucs\n",
    "\n",
    "# # Call function\n",
    "# aucs = k_folds_validation(df, 5)\n",
    "#     # Finally get the standard deviation\n",
    "#     # Standard deviation of list\n",
    "# # Using sum() + list comprehension\n",
    "# mean = sum(aucs) / len(aucs)\n",
    "# std = (sum([((x - mean) ** 2) for x in aucs]) / len(aucs))**0.5\n",
    "# std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9798 AUC with a standard deviation of 0.0194\n"
     ]
    }
   ],
   "source": [
    "# Question 5 - Using custom code with sklearn using cross_val_score\n",
    "CV = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "\n",
    "X_train, X_test, y_train, X_val, y_test, y_val = df_prep_and_split(df)\n",
    "\n",
    "# Run cross validation score with auc as the metric\n",
    "scores = cross_val_score(model, X_train, y_train, cv=CV, scoring='roc_auc')\n",
    "\n",
    "print(\"%0.4f AUC with a standard deviation of %0.4f\" % (scores.mean(), scores.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.01: [0.9767644956669347, 0.02362699622284424],\n",
       " 0.1: [0.9814630491459759, 0.018235770785871228],\n",
       " 1: [0.9798182305499379, 0.019422980153699733],\n",
       " 10: [0.9787496243593804, 0.01788478114639378]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Question 6\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "C = [0.01, 0.1, 1, 10]\n",
    "output = {}\n",
    "for value in C:\n",
    "    model = LogisticRegression(solver='liblinear', C=value, max_iter=1000)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=CV, scoring='roc_auc')\n",
    "    output[value] = [scores.mean(), scores.std()]\n",
    "\n",
    "# Get output of best value\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc5a08217b59f561bae803d66f14d54fb71480af2b8ed710ff58115b53376104"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
